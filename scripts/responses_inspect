#!/usr/bin/env python

import os
import argparse
import sqlite3
import numpy as np
import re
from datasets import Dataset
from pprint import pprint
from itertools import product
from tabulate import tabulate
from tqdm import tqdm
from difflib import ndiff

from IPython.terminal.embed import InteractiveShellEmbed

def main(args):
    pth = args.path
    con = sqlite3.connect(pth)
    cur = con.cursor()
    tables = list(list(zip(*cur.execute(
        'select name from sqlite_master where type="table";'
    ).fetchall()))[0])
    try:
        views = list(list(zip(*cur.execute(
            'select name from sqlite_master where type="view";'
        ).fetchall()))[0])
    except:
        views = []

    columns = dict()
    for name in tables:
        tbl_info = cur.execute(f"PRAGMA table_info({name});").fetchall()
        _, cols, _, _, _, _ = zip(*tbl_info)
        columns[name] = list(cols)
    for name in views:
        vw_info = cur.execute(f"PRAGMA table_info({name});").fetchall()
        _, cols, _, _, _, _ = zip(*vw_info)
        columns[name] = list(cols)

    print(f'creating view ...')
    query = (
        f"""
        CREATE VIEW IF NOT EXISTS all_data AS
        SELECT 
            R.rowid AS resp_id, R.model, R.temperature, P.template_name, 
            P.problem_id, P.template_id, P.sys_id, F.problem, F.answer, 
            P.prompt_text, R.response
        FROM responses R
        JOIN prompts P on R.prompt_id=P.rowid
        JOIN fitb_problems F on P.problem_id=F.rowid
        JOIN source_data C on F.ref_id=C.rowid
        """
    )
    res = cur.execute(query)

    keys = [
        'resp_id', 'model', 'temperature', 'template_name', 
        'problem_id', 'template_id', 'sys_id', 'problem', 'answer', 
        'prompt_text', 'response', 
    ]

    out_table = []

    print(f'retrieving template names ...')
    # get some list values
    res = cur.execute('SELECT DISTINCT template_name from prompts')
    template_names, = zip(*res.fetchall())
    print(f'retrieving model names ...')
    res = cur.execute('SELECT DISTINCT model from responses')
    model_names, = zip(*res.fetchall())

    #ds = make_all_data_ds(cur)
    #extract_answers(ds[1])
    res = cur.execute(
        f'select * from all_data where model="meta-llama/Llama-3.3-70B-Instruct"'
    )
    ds = make_ds(res, keys=keys)
    fltr = ds.filter(
        lambda x: '<ANSWER>' in x['response'] and '</ANSWER>' in x['response']
    )
    patterns = (
        r"<ANSWER>(.*?)</ANSWER>",
        r"<ANSWER>(.*?)<ANSWER>",
    )

    extr, diffs = extract_answers(
        fltr[0], 
        patterns=patterns,
        return_diffs=True,
    )
    

    ipshell = InteractiveShellEmbed()
    ipshell()

def extract_answers(
        sample: dict, 
        patterns=[], 
        blank_str='______',
        return_diffs=False
    ):
    response = sample['response']
    #extr = {'full': response}
    extr = dict()

    tags, texts = ['full'], [response]

    # convert to list if patterns is just a string
    if isinstance(patterns, str):
        patterns = [patterns]

    # extract using search patterns
    match_keys = []
    match_vals = []
    for i, pattern in enumerate(patterns):
        matches = re.findall(pattern, response)
        match_keys += [
            f'pattern:{i},pos:{k}' for k in range(len(matches))
        ]
        match_vals += matches
        # extr.update({
        #     f'pattern:{i},pos:{k}': match.strip()
        #     for k, match in enumerate(matches)
        # })
    tags += match_keys
    texts += match_vals

    diffs = list(ndiff(
        sample['problem'].split(), 
        response.split()
    ))

    # A = problem text, B = response text
    A_only = [word[2:] for word in diffs if word.startswith('- ')]
    B = [
        word[2:] for word in diffs 
        if re.match('^\+\s|^\s\s', word)
    ]
    B_only = [word[2:] for word in diffs if word.startswith('+ ')]

    tags.append('diff_seqs:all')
    texts.append(' '.join(B_only))

    # find uninterupted exclusive sub-sequences in text
    seqs = []
    candidate = ''
    for word in response.split():
        if word in B_only:
            candidate += f' {word}'
        elif candidate != '':
            seqs.append(candidate.strip())
            candidate = ''
    if candidate != '':
        seqs.append(candidate.strip())
    seqs = list(filter(lambda x: len(x.split()) > 3, seqs))

    tags += [f'diff_seqs:{i}' for i in range(len(seqs))]
    texts += seqs
    #extr.update({f'diff_seqs:{i}': seq for i, seq in enumerate(seqs)})
    lines = response.split('\n')
    lines = [line for line in lines if line != '']
    if len(lines) > 1:
        tags += [f'lines:{i}' for i in range(len(lines))]
        texts += lines

    # Matches numbered lists (e.g., "1. Item", "2) Item", "(3) Item")
    numbered_list_pattern = r'(?m)^\s*(?:\d+[\).]|\(\d+\))\s+(.+)$'
    
    # Matches bullet points (e.g., "- Item", "* Item", "• Item")
    bullet_list_pattern = r'(?m)^\s*[-•*]\s+(.+)$'
    
    matches = (
        re.findall(numbered_list_pattern, response) 
        + re.findall(bullet_list_pattern, response)
    )
    list_elements = [item.strip() for item in matches]
    tags += [f'list_el:{i}' for i in range(len(list_elements))]
    texts += list_elements

    matches = re.findall(r':\s*(.+)', response)
    tags += [f'post_colon:{i}' for i in range(len(matches))]
    texts += [match.strip() for match in matches]

    # Use left context of problem and right context of problem to match
    # the blank
    left_half, right_half = sample['problem'].split('______')
    matches = re.findall(
        f'{re.escape(left_half)}(.*?){re.escape(right_half)}', 
        response
    )
    tags += [f'context_match:{i}' for i in range(len(matches))]
    texts += [match.strip() for match in matches]

    ##############################
    # filter and reduction step #
    ##############################

    # instantiate text_set with strings we already know to filter out
    invalid_set = {
        '', response, blank_str,
        left_half.strip() + ' ' + right_half.strip(),
    }

    # combine tags that have matching text
    text_tag_map = {
        text: [] for text in texts if text not in invalid_set
    }
    for tag, text in zip(tags, texts):
        if text not in invalid_set:
            text_tag_map[text].append(tag)
    extr = {
        ','.join(tag_set): text 
        for text, tag_set 
        in text_tag_map.items()
    }

    if return_diffs:
        return extr, diffs
    else:
        return extr

def make_all_data_ds(cursor):
    keys = [
        'resp_id', 'model', 'temperature', 'template_name', 
        'problem_id', 'template_id', 'sys_id', 'problem', 'answer', 
        'prompt_text', 'response', 
    ]
    ds = make_ds(cursor.execute(f'select * from all_data'), keys)
    return ds

def cursor_generator(cursor, keys):
    for row in cursor:
        yield dict(zip(keys, row))
        
def make_ds(cursor, keys):
    return Dataset.from_dict(dict(zip(keys, zip(*cursor.fetchall()))))

def cur_gen(cur, batch_size=1000, keys=None):
    while True:
        batch = cur.fetchmany(batch_size)
        if not batch:  # No more rows to fetch
            break
        if keys:
            yield dict(zip(keys, zip(*batch)))
        else:
            yield batch

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('path', type=str)
    args = parser.parse_args()
    main(args)