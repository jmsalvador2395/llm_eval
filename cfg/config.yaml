datasets:
  all_sides: 
    type: "json"
    path: "{{project_root}}/data/ds/all_sides/test.json"
    aliases:
      Left: doc1
      Right: doc2
    references: 
      - "Ahmed_Intersection"
      - "Naman_Intersection"
      - "Helen_Intersection" 
      - "AllSides_Intersection"
  privacy_policy: 
    type: "csv"
    path: "{{project_root}}/data/ds/privacy_policy/3p_data.csv"
    aliases:
      Company_1: doc1
      Company_2: doc2
    references: 
      - "Annotator1"
      - "Annotator2"
      - "Annotator3"
  stanfordnlp/sst2:
    text_column: "sentence"
    split: "test"
  abisee/cnn_dailymail:
    text_column: "article"
    split: "test"
    args:
      - "1.0.0"
  sind:
    path: "{{project_root}}/data/ds/sind"
    file_map:
      train: "train.tsv"
      dev: "dev.tsv"
      test: "test.tsv"
    text_column: "text"
    split:
      - "test"
      - "dev"
  roc:
    path: "{{project_root}}/data/ds/ROCStories"
    text_column: "text"
    split: 'test'
  wikipedia:
    test_size: 10000
    split:
      - "test"
    text_column: "text"
    args:
      - "20231101.en"
    min_sents: 10

    
  acl_abstracts:
    type: "json"
    path: "{{project_root}}/data/ACL_titles_abstracts_dataset/acl_abstracts.json"
    text_column: "text"

infill:
  seed: 100
  ds_cache: "{{project_root}}/data/cache"
  save_dir: "{{project_root}}/data/results"
  batch_size: 1000
  prompt_templates:
  target_data:
    - "roc"
    - "sind"
    - "abisee/cnn_dailymail"
    - "wikipedia"
  split_tokens:
    roc: "<eos>"
    sind: "<eos>"
  num_proc: 8
  chunk_size: 32
  prompt_templates:
    sys: "{{project_root}}/cfg/prompts/fitb_system.yaml"
    fitb_l0: "{{project_root}}/cfg/prompts/fitb_l0.yaml" 
    fitb_l1: "{{project_root}}/cfg/prompts/fitb_l1.yaml" 
    fitb_l2: "{{project_root}}/cfg/prompts/fitb_l2.yaml" 
    fitb_l3: "{{project_root}}/cfg/prompts/fitb_l3.yaml" 
    fitb_l4: "{{project_root}}/cfg/prompts/fitb_l4.yaml" 
  max_blank_sents: 5
  max_blank_words: 0
  one_of_each: True
  kwargs:
    bertscore:
      lang: "en"
    rouge:
      use_aggregator: False
  temps:
    - 0.7
    - 0.5
    - 0.3

resp_coll:
  ds_cache: "{{project_root}}/data/cache"
  save_dir: "{{project_root}}/data/results"
  num_attempts: 3
  checkpoint_interval: 50
  prompt_templates: 
    sys: "{{project_root}}/cfg/prompts/system.yaml"
    icl: "{{project_root}}/cfg/prompts/in_context_learning.yaml"
    l0: "{{project_root}}/cfg/prompts/teler_l0.yaml"
    l1: "{{project_root}}/cfg/prompts/teler_l1.yaml"
    l2: "{{project_root}}/cfg/prompts/teler_l2.yaml"
    l3: "{{project_root}}/cfg/prompts/teler_l3.yaml"
    l4: "{{project_root}}/cfg/prompts/teler_l4.yaml"
  models:
    - microsoft/Phi-3-mini-4k-instruct
    - microsoft/Phi-3-mini-128k-instruct
    - meta-llama/Meta-Llama-3-8B-Instruct
    - meta-llama/Llama-2-7b-chat-hf
    - meta-llama/Llama-2-13b-chat-hf
    - meta-llama/Llama-3.2-1B-Instruct

eval:
  metrics:
    - "rouge"
    #- "semf1"
    #- "bertscore"
    #- "fans"
  save_dir: "{{project_root}}/data/results/"

model_params:
  model_cache: "{{project_root}}/data/llm_cache"
  meta-llama/Llama-3.2-1B-Instruct:
    max_length: 48000
  meta-llama/Llama-3.2-3B-Instruct:
    max_length: 48000
  meta-llama/Llama-3.1-8B-Instruct:
    max_length: 48000

unit_test: 
  cases:
    #- "eval"
    - "llm-responses"
    #- "teler"

