#!/usr/bin/env python

import os
import argparse
import sqlite3
import numpy as np
import re
from datasets import Dataset
from pprint import pprint
from itertools import product
from tabulate import tabulate
from tqdm import tqdm
from difflib import ndiff

from IPython.terminal.embed import InteractiveShellEmbed

def main(args):
    pth = args.path
    con = sqlite3.connect(pth)
    cur = con.cursor()
    tables = list(list(zip(*cur.execute(
        'select name from sqlite_master where type="table";'
    ).fetchall()))[0])
    try:
        views = list(list(zip(*cur.execute(
            'select name from sqlite_master where type="view";'
        ).fetchall()))[0])
    except:
        views = []

    columns = dict()
    for name in tables:
        tbl_info = cur.execute(f"PRAGMA table_info({name});").fetchall()
        _, cols, _, _, _, _ = zip(*tbl_info)
        columns[name] = list(cols)
    for name in views:
        vw_info = cur.execute(f"PRAGMA table_info({name});").fetchall()
        _, cols, _, _, _, _ = zip(*vw_info)
        columns[name] = list(cols)

    print(f'(creating view ...')
    query = (
        f"""
        CREATE VIEW IF NOT EXISTS all_data AS
        SELECT 
            R.rowid AS resp_id, R.model, R.temperature, P.template_name, 
            P.problem_id, P.template_id, P.sys_id, F.problem, F.answer, 
            P.prompt_text, R.response
        FROM responses R
        JOIN prompts P on R.prompt_id=P.rowid
        JOIN fitb_problems F on P.problem_id=F.rowid
        JOIN source_data C on F.ref_id=C.rowid
        """
    )
    res = cur.execute(query)

    keys = [
        'resp_id', 'model', 'temperature', 'template_name', 
        'problem_id', 'template_id', 'sys_id', 'problem', 'answer', 
        'prompt_text', 'response', 
    ]

    out_table = []

    print(f'retrieving template names ...')
    # get some list values
    res = cur.execute('SELECT DISTINCT template_name from prompts')
    template_names, = zip(*res.fetchall())
    print(f'retrieving model names ...')
    res = cur.execute('SELECT DISTINCT model from responses')
    model_names, = zip(*res.fetchall())

    #ds = make_all_data_ds(cur)
    #extract_answers(ds[1])
    res = cur.execute(
        f'select * from all_data where model="meta-llama/Llama-3.3-70B-Instruct"'
    )
    ds = make_ds(res, keys=keys)
    fltr = ds.filter(lambda x: '<ANSWER>' in x['response'] and '</ANSWER>' in x['response'])
    extr, diffs = extract_answers(fltr[0], patterns=r'<ANSWER>(.*?)</ANSWER>')
    

    ipshell = InteractiveShellEmbed()
    ipshell()

def extract_answers(sample: dict, patterns=[]):
    extr = dict()
    extr['full'] = sample['response']
    diffs = list(ndiff(
        sample['problem'].split(), 
        sample['response'].split()
    ))

    # A = problem text, B = response text
    A_only = [word[2:] for word in diffs if word.startswith('- ')]
    #both = [word[2:] for word in diffs if word.startswith('  ')]
    B = [
        word[2:] for word in diffs 
        if re.match('^\+\s|^\s\s', word)
    ]
    B_only = [word[2:] for word in diffs if word.startswith('+ ')]
    extr['all_exclusive'] = ' '.join(B_only)

    # find uninterupted exclusive sub-sequences in text
    seqs = []
    candidate = ''
    for word in sample['response'].split():
        if word in B_only:
            candidate += f' {word}'
        elif candidate != '':
            seqs.append(candidate.strip())
            candidate = ''
    if candidate != '':
        seqs.append(candidate.strip())
    seqs = list(filter(lambda x: len(x.split()) > 3, seqs))
    extr.update({f'diff_seqs:{i}': seq for i, seq in enumerate(seqs)})
    lines = sample['response'].split('\n')
    lines = [line for line in lines if line != '']
    if len(lines) > 1:
        extr.update({f'lines:{i}': seq for i, seq in enumerate(lines)})

    # convert to list if patterns is just a string
    if isinstance(patterns, str):
        patterns = [patterns]

    # extract using search patterns
    for i, pattern in enumerate(patterns):
        matches = re.findall(pattern, sample['response'])
        extr.update({
            f'pattern:{i},pos:{k}': match 
            for k, match in enumerate(matches)
        })

    return extr, diffs


def make_all_data_ds(cursor):
    keys = [
        'resp_id', 'model', 'temperature', 'template_name', 
        'problem_id', 'template_id', 'sys_id', 'problem', 'answer', 
        'prompt_text', 'response', 
    ]
    ds = make_ds(cursor.execute(f'select * from all_data'), keys)
    return ds

def cursor_generator(cursor, keys):
    for row in cursor:
        yield dict(zip(keys, row))
        
def make_ds(cursor, keys):
    return Dataset.from_dict(dict(zip(keys, zip(*cursor.fetchall()))))

def cur_gen(cur, batch_size=1000, keys=None):
    while True:
        batch = cur.fetchmany(batch_size)
        if not batch:  # No more rows to fetch
            break
        if keys:
            yield dict(zip(keys, zip(*batch)))
        else:
            yield batch

if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('path', type=str)
    args = parser.parse_args()
    main(args)