
api_keys:
    palm: "<CHANGE_ME>"

response_collection:
  ds_cache: "{{project_root}}/data/cache"
  prompt_template: "{{project_root}}/cfg/prompts/prompts01.yaml"
  models:
  - "mistralai/Mistral-7B-Instruct-v0.1"
  - "mistralai/Mistral-7B-Instruct-v0.2"
  - "lmsys/vicuna-7b-v1.5"
  - "lmsys/vicuna-7b-v1.5-16k"
  - "lmsys/vicuna-13b-v1.5"
  - "lmsys/vicuna-13b-v1.5-16k"
  - "mosaicml/mpt-7b-instruct"
  - "mosaicml/mpt-7b-chat"
  - "meta-llama/Llama-2-7b-chat-hf"
  - "meta-llama/Llama-2-13b-chat-hf"
  - "mosaicml/mpt-30b-chat"
  - "mosaicml/mpt-30b-instruct"
  #- "tiiuae/falcon-7b-instruct"
  #- "gpt-3.5-turbo"
  #- "gpt-4"
  #- "chat-bison-001"
  #- "gemini-pro"
  #- "meta-llama/Llama-2-70b-chat-hf"
  datasets:
    all_sides: 
      type: "json"
      path: "{{project_root}}/data/all_sides/test.json"
      ref_col_names: 
        - "Ahmed_Intersection"
        - "Naman_Intersection"
        - "Helen_Intersection" 
        - "AllSides_Intersection"
    privacy_policy: 
      type: "csv"
      path: "{{project_root}}/data/privacy_policy/3p_data.csv"
      ref_col_names: 
        - "Annotator1"
        - "Annotator2"
        - "Annotator3"
  save_dir: "{{project_root}}/data/results"
  num_attempts: 3

eval:
  metrics:
    - "rouge"
    - "sem-f1"
    - "bert_score"
    #- "fans"
  save_dir: "{{project_root}}/data/results/"

model_params:
  #model_cache: "{{project_root}}/data/llm_cache"
  model_cache: "/data/shared/llm_cache"
  #model_cache: "/data/john/cache"
  use_sampling_params: False
  max_length: 2048
  num_output_tokens: 512
  temperature: 0.8
  batch_size: 2
  num_devices: 4
  #dtype: "float16"
  dtype: "auto"

unit_test: 
  cases:
    #- "eval"
    - "llm-responses"
    #- "teler"

